{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Depuper Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example of see respository for real test_umi_dict.txt \n",
    "CTGTTCAC\n",
    "CTGTTCAG\n",
    "CTGTTCAT\n",
    "CTGTTCAA\n",
    "CTGTTCTA\n",
    "CTGTTCTC\n",
    "CTGTTCTG\n",
    "CTGTTCTT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example of see respository for real test_sam.txt\n",
    "changed second entry back and forth from flag 1 to 0 to test for paired end on real file\n",
    "\n",
    "@HD\tVN:1.0\tSO:unsorted\n",
    "@PG\tID:GSNAP\tPN:gsnap\tVN:2017-10-12\tCL:gsnap.avx2 --gunzip -t 26 -A sam -m 5 -d mm10_chroms -D /projects/bgmp/coonrod/mmu/INTEL -s /projects/bgmp/coonrod/mmu/INTEL/mm10_chroms/mm10_chroms.maps/Mus_musculus.GRCm38.89.splicesites.iit --split-output=/projects/bgmp/coonrod/deduper/gsnap//Datset1 /projects/bgmp/coonrod/deduper//Dataset1.fastq_dups.gz\n",
    "@SQ\tSN:1\tLN:195471971\n",
    "@SQ\tSN:2\tLN:182113224\n",
    "@SQ\tSN:3\tLN:160039680\n",
    "@SQ\tSN:4\tLN:156508116\n",
    "@SQ\tSN:5\tLN:151834684\n",
    "@SQ\tSN:6\tLN:149736546\n",
    "@SQ\tSN:7\tLN:145441459\n",
    "@SQ\tSN:8\tLN:129401213\n",
    "@SQ\tSN:9\tLN:124595110\n",
    "@SQ\tSN:10\tLN:130694993\n",
    "@SQ\tSN:11\tLN:122082543\n",
    "@SQ\tSN:12\tLN:120129022\n",
    "@SQ\tSN:13\tLN:120421639\n",
    "@SQ\tSN:14\tLN:124902244\n",
    "@SQ\tSN:15\tLN:104043685\n",
    "@SQ\tSN:16\tLN:98207768\n",
    "@SQ\tSN:17\tLN:94987271\n",
    "@SQ\tSN:18\tLN:90702639\n",
    "@SQ\tSN:19\tLN:61431566\n",
    "@SQ\tSN:X\tLN:171031299\n",
    "@SQ\tSN:Y\tLN:91744698\n",
    "@SQ\tSN:MT\tLN:16299\n",
    "1)NS500451:single-end:HWKTMBGXX:1:11101:24260:1121:CTGTTCAC\t0\t1\t100\t36\t5S10M5I5M10N5D71M40S\t*\t0\t0\tTCCACCACAATCTTACCATCCTTCCTCCAGACCACATCGCGTTCTTTGTTCAACTCACAGCTCAAGTACAA\t6AEEEEEEAEEAEEEEAAEEEEEEEEEAEEAEEAAEE<EEEEEEEEEAEEEEEEEAAEEAAAEAEEAEAE/\tMD:Z:71\tNH:i:1\tHI:i:1\tNM:i:0\tSM:i:36\tXQ:i:40\tX2:i:0\tXO:Z:UU\n",
    "2)NS500451:paired-end:HWKTMBGXX:1:11101:24260:1121:CTGTTCAG\t0\t1\t100\t36\t71M\t*\t0\t0\tTCCACCACAATCTTACCATCCTTCCTCCAGACCACATCGCGTTCTTTGTTCAACTCACAGCTCAAGTACAA\t6AEEEEEEAEEAEEEEAAEEEEEEEEEAEEAEEAAEE<EEEEEEEEEAEEEEEEEAAEEAAAEAEEAEAE/\tMD:Z:71\tNH:i:1\tHI:i:1\tNM:i:0\tSM:i:36\tXQ:i:40\tX2:i:0\tXO:Z:UU\n",
    "3)NS500451:umi-in-dictionary:HWKTMBGXX:1:11101:24260:1121:CTGTTCTT\t0\t3\t100\t36\t71M\t*\t0\t0\tTCCACCACAATCTTACCATCCTTCCTCCAGACCACATCGCGTTCTTTGTTCAACTCACAGCTCAAGTACAA\t6AEEEEEEAEEAEEEEAAEEEEEEEEEAEEAEEAAEE<EEEEEEEEEAEEEEEEEAAEEAAAEAEEAEAE/\tMD:Z:71\tNH:i:1\tHI:i:1\tNM:i:0\tSM:i:36\tXQ:i:40\tX2:i:0\tXO:Z:UU\n",
    "4)NS500451:umi-not-in-dictionary:HWKTMBGXX:1:11101:24260:1121:TTTTTTTT\t16\t4\t100\t36\t71M\t*\t0\t0\tTCCACCACAATCTTACCATCCTTCCTCCAGACCACATCGCGTTCTTTGTTCAACTCACAGCTCAAGTACAA\t6AEEEEEEAEEAEEEEAAEEEEEEEEEAEEAEEAAEE<EEEEEEEEEAEEEEEEEAAEEAAAEAEEAEAE/\tMD:Z:71\tNH:i:1\tHI:i:1\tNM:i:0\tSM:i:36\tXQ:i:40\tX2:i:0\tXO:Z:UU\n",
    "5)NS500451:flag-is-forward:HWKTMBGXX:1:11101:24260:1121:CTGTTCAT\t16\t5\t100\t36\t71M\t*\t0\t0\tTCCACCACAATCTTACCATCCTTCCTCCAGACCACATCGCGTTCTTTGTTCAACTCACAGCTCAAGTACAA\t6AEEEEEEAEEAEEEEAAEEEEEEEEEAEEAEEAAEE<EEEEEEEEEAEEEEEEEAAEEAAAEAEEAEAE/\tMD:Z:71\tNH:i:1\tHI:i:1\tNM:i:0\tSM:i:36\tXQ:i:40\tX2:i:0\tXO:Z:UU\n",
    "6)NS500451:flag-is-reverse:HWKTMBGXX:1:11101:24260:1121:CTGTTCAA\t0\t6\t100\t36\t71M\t*\t0\t0\tTCCACCACAATCTTACCATCCTTCCTCCAGACCACATCGCGTTCTTTGTTCAACTCACAGCTCAAGTACAA\t6AEEEEEEAEEAEEEEAAEEEEEEEEEAEEAEEAAEE<EEEEEEEEEAEEEEEEEAAEEAAAEAEEAEAE/\tMD:Z:71\tNH:i:1\tHI:i:1\tNM:i:0\tSM:i:36\tXQ:i:40\tX2:i:0\tXO:Z:UU\n",
    "7)NS500451:forward&has-s:HWKTMBGXX:1:11101:24260:1121:CTGTTCTA\t16\t6\t100\t36\t40S71M\t*\t0\t0\tTCCACCACAATCTTACCATCCTTCCTCCAGACCACATCGCGTTCTTTGTTCAACTCACAGCTCAAGTACAA\t6AEEEEEEAEEAEEEEAAEEEEEEEEEAEEAEEAAEE<EEEEEEEEEAEEEEEEEAAEEAAAEAEEAEAE/\tMD:Z:71\tNH:i:1\tHI:i:1\tNM:i:0\tSM:i:36\tXQ:i:40\tX2:i:0\tXO:Z:UU\n",
    "8)NS500451:forward&noaction:HWKTMBGXX:1:11101:24260:1121:CTGTTCTC\t0\t8\t100\t36\t71M40S\t*\t0\t0\tTCCACCACAATCTTACCATCCTTCCTCCAGACCACATCGCGTTCTTTGTTCAACTCACAGCTCAAGTACAA\t6AEEEEEEAEEAEEEEAAEEEEEEEEEAEEAEEAAEE<EEEEEEEEEAEEEEEEEAAEEAAAEAEEAEAE/\tMD:Z:71\tNH:i:1\tHI:i:1\tNM:i:0\tSM:i:36\tXQ:i:40\tX2:i:0\tXO:Z:UU\n",
    "9)NS500451:forward&has-s:HWKTMBGXX:1:11101:24260:1121:CTGTTCTC\t16\t9\t100\t36\t5S71M40S\t*\t0\t0\tTCCACCACAATCTTACCATCCTTCCTCCAGACCACATCGCGTTCTTTGTTCAACTCACAGCTCAAGTACAA\t6AEEEEEEAEEAEEEEAAEEEEEEEEEAEEAEEAAEE<EEEEEEEEEAEEEEEEEAAEEAAAEAEEAEAE/\tMD:Z:71\tNH:i:1\tHI:i:1\tNM:i:0\tSM:i:36\tXQ:i:40\tX2:i:0\tXO:Z:UU\n",
    "10)NS500451:forward&has-s:HWKTMBGXX:1:11101:24260:1121:CTGTTCTC\t0\t10\t100\t36\t5S71M40S\t*\t0\t0\tTCCACCACAATCTTACCATCCTTCCTCCAGACCACATCGCGTTCTTTGTTCAACTCACAGCTCAAGTACAA\t6AEEEEEEAEEAEEEEAAEEEEEEEEEAEEAEEAAEE<EEEEEEEEEAEEEEEEEAAEEAAAEAEEAEAE/\tMD:Z:71\tNH:i:1\tHI:i:1\tNM:i:0\tSM:i:36\tXQ:i:40\tX2:i:0\tXO:Z:UU\n",
    "11)NS500451:forward&has-s,dupe:HWKTMBGXX:1:11101:24260:1121:CTGTTCTC\t0\t10\t100\t36\t5S71M40S\t*\t0\t0\tTCCACCACAATCTTACCATCCTTCCTCCAGACCACATCGCGTTCTTTGTTCAACTCACAGCTCAAGTACAA\t6AEEEEEEAEEAEEEEAAEEEEEEEEEAEEAEEAAEE<EEEEEEEEEAEEEEEEEAAEEAAAEAEEAEAE/\tMD:Z:71\tNH:i:1\tHI:i:1\tNM:i:0\tSM:i:36\tXQ:i:40\tX2:i:0\tXO:Z:UU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test code\n",
    "import re\n",
    "import sys\n",
    "import os\n",
    "\n",
    "#################################################################################################################\n",
    "#creating a dictionary with umis\n",
    "\n",
    "#this is the path to the test dictionary with umis\n",
    "test_umi_dict=\"/Users/mandiedriskill/GitHub/2018_Bi621/deduper-mandiedriskill/test_umi_dict.txt\"\n",
    "#creating an empty dictionary for umis\n",
    "UMI_dict={}\n",
    "#read the lines in the file\n",
    "for line in open(test_umi_dict).readlines():\n",
    "    #stripping the lines in the file\n",
    "    umi=line.strip()\n",
    "    #setting the dictionary. Keys are umis and values are none\n",
    "    UMI_dict[umi]=None\n",
    "    #check dictionary to make sure it looks right\n",
    "    #print(UMI_dict)\n",
    "\n",
    "#################################################################################################################\n",
    "#creating counters, empty variables and dictionaries\n",
    "\n",
    "#creating a counter to keep track of lines in the test file\n",
    "ctr=1\n",
    "\n",
    "#creating a dictionary to keep track of unique reads\n",
    "unique_dict={}\n",
    "#setting the variable to empty\n",
    "current_rname=\"\"\n",
    "#setting the variable to empty\n",
    "previous_rname=\"\"\n",
    "\n",
    "#creating counters for unmis not in dictionary, forward reads, reverse reads, and unique/deduped reads\n",
    "ctr_umi_notin_dict=0\n",
    "forward_reads=0\n",
    "reverse_reads=0\n",
    "unique_reads=0\n",
    "###################################################################################################################\n",
    "#creating functions\n",
    "\n",
    "#creating a function for determining if the read is paired-end\n",
    "def pair_end_reads(flag):\n",
    "    #if the reads are paired-ended then do stuff\n",
    "    if((int(flag) & 1) == 1):\n",
    "        #exiting the code and outputting an error code\n",
    "        sys.exit(\"Error, file contains pair-end reads\")\n",
    "    else:\n",
    "        #if the reads is not paired-end then keep doing stuff\n",
    "        return True \n",
    "    \n",
    "#creating a function for adjusting the forward postition and making a unique string\n",
    "def forward_adjust(pos):\n",
    "    #setting variable to the left S\n",
    "    softclip=re.search(r\"^(\\d+)S\", cigar)\n",
    "    # if not S is found then do stuff \n",
    "    if softclip is None:\n",
    "        #softclip does nothing if it has no value\n",
    "        softclip=softclip\n",
    "    else:\n",
    "        #if softclip has value then it is set to group 1 integer\n",
    "        s1=int(softclip.group(1))\n",
    "        #the position is adjusted if there is a integer\n",
    "        pos=pos-s1\n",
    "    \n",
    "    #spring is set to a combination of rname,UMI,POS,and Plus\n",
    "    string=current_rname+UMI+str(pos)+\"Plus\"\n",
    "    #returning the funciton\n",
    "    return string\n",
    "\n",
    "#creating a function for adjusting the reverse postition and making a unique string\n",
    "def reverse_adjust(pos):\n",
    "    #the position is adjusted with the following values\n",
    "    pos=pos+total_S+total_M+total_D+total_N-1\n",
    "\n",
    "    #string is set to a combinaiton of rname,UMI,POS, and Minus\n",
    "    string=current_rname+UMI+str(pos)+\"Minus\"\n",
    "    #returning the function\n",
    "    return string\n",
    "\n",
    "###################################################################################################################\n",
    "#opening the test files and writing to output files.\n",
    "\n",
    "file = \"/Users/mandiedriskill/GitHub/2018_Bi621/deduper-mandiedriskill/test_sam.txt\"\n",
    "o = \"test_file\"\n",
    "\n",
    "with open (file, \"r\") as fh, \\\n",
    "open(o + '_deduped.sam', 'w') as PCR_removed, \\\n",
    "open(o + '_undetermine.sam', 'w') as undetermined, \\\n",
    "open(o + '_count_data', 'w') as count_data:\n",
    "    \n",
    "###################################################################################################################\n",
    "#splitting the line into parts and keeping track of line to erase dictionary when a new chromosome is encountered\n",
    "\n",
    "    \n",
    "    for line in fh:\n",
    "        #if line starts with @ do stuff\n",
    "        if line.startswith(\"@\"):\n",
    "            #writing the @ lines to the pcr_removed file\n",
    "            PCR_removed.write(line)\n",
    "            continue\n",
    "        else:\n",
    "            #splitting the line by tabs so parts can be grabbed\n",
    "            parts = line.split(\"\\t\")#this splits all the colums in the line into lists(parts)\n",
    "            #making sure parts work\n",
    "            #print(parts)\n",
    "            #qname is parts 0\n",
    "            qname=parts[0]\n",
    "            #making sure qname works\n",
    "            print(qname)\n",
    "            #flag is parts 1\n",
    "            flag=parts[1]\n",
    "            #making sure flag works\n",
    "            #print(flag)\n",
    "            #using the paired end function\n",
    "            pair_end_reads(flag)\n",
    "            #current rname is parts 2\n",
    "            current_rname=parts[2]\n",
    "            #making sure current_rname works\n",
    "            #print(current_rname)\n",
    "            \n",
    "            #if the counter is on line 1 then do stuff\n",
    "            if ctr==1:\n",
    "                #setting previous name to current name\n",
    "                previous_rname=current_rname\n",
    "                #making sure previous_rname is working\n",
    "                #print(previous_rname)\n",
    "            #keeping track of ctr lines    \n",
    "            ctr+=1\n",
    "            \n",
    "            #if the current_rname doesn't equal previous_rname then do stuff\n",
    "            if current_rname != previous_rname:\n",
    "                #reinitializing previous_rname to current_rname\n",
    "                previous_rname=current_rname\n",
    "                #deleting the unique_dict when a new chromosome is encountered\n",
    "                del unique_dict\n",
    "                #reinitializing the dictionary\n",
    "                unique_dict={}\n",
    "            \n",
    "            \n",
    "            pos=int(parts[3])\n",
    "            #making sure pos is correct\n",
    "            #print(pos)\n",
    "            cigar=parts[5]\n",
    "            #making sure cigar is correct\n",
    "            #print(cigar)\n",
    "            rnext=parts[6] \n",
    "            #making sure rnext is correct\n",
    "            #print(rnext)\n",
    "            \n",
    "###################################################################################################################\n",
    "#isolating and suming Ds, Ms, Is, and end Ss.\n",
    "            \n",
    "            #finding all end Ss \n",
    "            S = re.findall(r'(\\d+)S$', cigar)#finds all end S's\n",
    "            #making sure S is correct\n",
    "            #print(S)\n",
    "            #turning Ss into integers\n",
    "            S=list(map(int,S))\n",
    "            #making sure S is correct\n",
    "            #print(S)\n",
    "            #summing all the Ss\n",
    "            total_S = sum([int(i) for i in S])\n",
    "            #making sure total_S is correct\n",
    "            #print(total_S)\n",
    "            \n",
    "            #finding all Ms\n",
    "            M = re.findall(r\"(\\d+)M\", cigar)\n",
    "            #making sure M is correct\n",
    "            #print(M)\n",
    "            #turning Ms into integers\n",
    "            M = list(map(int,M))\n",
    "            #making sure M is correct\n",
    "            #print(M)\n",
    "            #summing all the Ms\n",
    "            total_M = sum([int(i) for i in M])\n",
    "            #making sure total_M is correct\n",
    "            #print(total_M)\n",
    "            \n",
    "            \n",
    "            #finding all Ds\n",
    "            D = re.findall(r\"(\\d+)D\", cigar)\n",
    "            #making sure D is correct\n",
    "            #print(D)\n",
    "            #turning Ds into integers\n",
    "            D = list(map(int,D))\n",
    "            #making sure D is correct\n",
    "            #print(D)\n",
    "            #summing all the Ds\n",
    "            total_D = sum([int(i) for i in D])\n",
    "            #making sure total_D is correct\n",
    "            #print(total_D)\n",
    "            \n",
    "            #finding all Ns\n",
    "            N = re.findall(r\"(\\d+)N\", cigar)\n",
    "            #making sure N is correct\n",
    "            #print(N)\n",
    "            #turning Ns into integers\n",
    "            N = list(map(int,N))\n",
    "            #making sure N is correct\n",
    "            #print(N)\n",
    "            #summing all the Ns\n",
    "            total_N = sum([int(i) for i in N])\n",
    "            #making sure total_N is correct\n",
    "            #print(total_N)\n",
    "            \n",
    "            #splitting qname into parts to isolate UMI\n",
    "            qname_parts=qname.split(\":\")\n",
    "            #making sure qname is correct\n",
    "            #print(qname)\n",
    "            #Setting the umi to a variable\n",
    "            UMI=qname_parts[7]\n",
    "            #making sure UMI is correct\n",
    "            #print(UMI)\n",
    "            \n",
    "###################################################################################################################\n",
    "                           \n",
    "            #If the UMI is not in the dictionary then do stuff\n",
    "            if UMI not in UMI_dict.keys():\n",
    "                #keeping track of how many UMIs are not in the dictionary\n",
    "                ctr_umi_notin_dict+=1\n",
    "                #making sure correct lines are going into the dictionary\n",
    "                #print(line)\n",
    "                #writing the reads with bad UMIs to a undetermined file\n",
    "                undetermined.write(line)\n",
    "            else:\n",
    "                #If the UMI is in the dictionary then do stuff\n",
    "                if UMI in UMI_dict.keys():\n",
    "                    #making sure correct lines are still there\n",
    "                    #print(line)\n",
    "\n",
    "###################################################################################################################\n",
    "# Forward strand     \n",
    "                    #if forward stand then do stuff\n",
    "                    if((int(flag) & 16) != 16):\n",
    "                        #counting the number for forward reads\n",
    "                        forward_reads+=1\n",
    "                        #setting string to the adjusted forward position\n",
    "                        string=forward_adjust(pos)\n",
    "                        #making sure pos was adjusted and string is correct\n",
    "                        #print(string)\n",
    "                        #making sure corerct line are being used for forward function\n",
    "                        #print(line)\n",
    "\n",
    "###################################################################################################################\n",
    "# reverse strand\n",
    "                    #if reverse stand then do stuff\n",
    "                    if((int(flag) & 16) == 16):\n",
    "                        #counting the number of reverse reads\n",
    "                        reverse_reads+=1\n",
    "                        #setting string to the adjusted reverse potition\n",
    "                        string=reverse_adjust(pos)\n",
    "                        #making sure pos was adjusted and string is correct \n",
    "                        #print(string)\n",
    "                        #making sure corerct line are being used for reverse function\n",
    "                        #print(line)\n",
    "                        \n",
    "###################################################################################################################\n",
    "#Filling the dictionary with unique reads and writing them to a deduped file\n",
    "                    \n",
    "                    #if unique string not in the dictionary then do stuff\n",
    "                    if string not in unique_dict:\n",
    "                        #keeping track of the number of unique/dedpued reads\n",
    "                        unique_reads+=1\n",
    "                        #filling the dictionary with unique reads (keys) and values as none\n",
    "                        unique_dict[string]=None\n",
    "                        #making sure dicitonary is putting in unique reads and dumping dictionary for new chrom.\n",
    "                        print(unique_dict)\n",
    "                        #writing lines that are unique\n",
    "                        PCR_removed.write(line)\n",
    "                            \n",
    "\n",
    "###################################################################################################################\n",
    "    #writing count information to a count_data file.\n",
    "    count_data.write(\"{}\\n{}\\n{}\\n{}\\n{}\\n{}\\n{}\\n{}\\n\".format(\"UMI Not Found in Dictionary\", ctr_umi_notin_dict, \\\n",
    "                                                               \"Number of Forward Reads\", forward_reads, \\\n",
    "                                                               \"Number of Reverse Reads\",  reverse_reads, \\\n",
    "                                                               \"Number of Unique Reads Found\", unique_reads)) \n",
    "#making sure count data is correct.\n",
    "print(\"UMI Not Found in Dictionary\", ctr_umi_notin_dict)\n",
    "print(\"Number of Forward Reads\", forward_reads)\n",
    "print(\"Number of Reverse Reads\",  reverse_reads)\n",
    "print(\"Number of Unique Reads Found\", unique_reads)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test output\n",
    "cat test_file_count_data \n",
    "UMI Not Found in Dictionary\n",
    "1\n",
    "Number of Forward Reads\n",
    "7\n",
    "Number of Reverse Reads\n",
    "3\n",
    "Number of Unique Reads Found\n",
    "9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test output\n",
    "cat test_file_deduped.sam \n",
    "@HD\tVN:1.0\tSO:unsorted\n",
    "@PG\tID:GSNAP\tPN:gsnap\tVN:2017-10-12\tCL:gsnap.avx2 --gunzip -t 26 -A sam -m 5 -d mm10_chroms -D /projects/bgmp/coonrod/mmu/INTEL -s /projects/bgmp/coonrod/mmu/INTEL/mm10_chroms/mm10_chroms.maps/Mus_musculus.GRCm38.89.splicesites.iit --split-output=/projects/bgmp/coonrod/deduper/gsnap//Datset1 /projects/bgmp/coonrod/deduper//Dataset1.fastq_dups.gz\n",
    "@SQ\tSN:1\tLN:195471971\n",
    "@SQ\tSN:2\tLN:182113224\n",
    "@SQ\tSN:3\tLN:160039680\n",
    "@SQ\tSN:4\tLN:156508116\n",
    "@SQ\tSN:5\tLN:151834684\n",
    "@SQ\tSN:6\tLN:149736546\n",
    "@SQ\tSN:7\tLN:145441459\n",
    "@SQ\tSN:8\tLN:129401213\n",
    "@SQ\tSN:9\tLN:124595110\n",
    "@SQ\tSN:10\tLN:130694993\n",
    "@SQ\tSN:11\tLN:122082543\n",
    "@SQ\tSN:12\tLN:120129022\n",
    "@SQ\tSN:13\tLN:120421639\n",
    "@SQ\tSN:14\tLN:124902244\n",
    "@SQ\tSN:15\tLN:104043685\n",
    "@SQ\tSN:16\tLN:98207768\n",
    "@SQ\tSN:17\tLN:94987271\n",
    "@SQ\tSN:18\tLN:90702639\n",
    "@SQ\tSN:19\tLN:61431566\n",
    "@SQ\tSN:X\tLN:171031299\n",
    "@SQ\tSN:Y\tLN:91744698\n",
    "@SQ\tSN:MT\tLN:16299\n",
    "1)NS500451:single-end:HWKTMBGXX:1:11101:24260:1121:CTGTTCAC\t0\t1\t100\t36\t5S10M5I5M10N5D71M40S\t*\t0\t0\tTCCACCACAATCTTACCATCCTTCCTCCAGACCACATCGCGTTCTTTGTTCAACTCACAGCTCAAGTACAA\t6AEEEEEEAEEAEEEEAAEEEEEEEEEAEEAEEAAEE<EEEEEEEEEAEEEEEEEAAEEAAAEAEEAEAE/\tMD:Z:71\tNH:i:1\tHI:i:1\tNM:i:0\tSM:i:36\tXQ:i:40\tX2:i:0\tXO:Z:UU\n",
    "2)NS500451:paired-end:HWKTMBGXX:1:11101:24260:1121:CTGTTCAG\t0\t1\t100\t36\t71M\t*\t0\t0\tTCCACCACAATCTTACCATCCTTCCTCCAGACCACATCGCGTTCTTTGTTCAACTCACAGCTCAAGTACAA\t6AEEEEEEAEEAEEEEAAEEEEEEEEEAEEAEEAAEE<EEEEEEEEEAEEEEEEEAAEEAAAEAEEAEAE/\tMD:Z:71\tNH:i:1\tHI:i:1\tNM:i:0\tSM:i:36\tXQ:i:40\tX2:i:0\tXO:Z:UU\n",
    "3)NS500451:umi-in-dictionary:HWKTMBGXX:1:11101:24260:1121:CTGTTCTT\t0\t3\t100\t36\t71M\t*\t0\t0\tTCCACCACAATCTTACCATCCTTCCTCCAGACCACATCGCGTTCTTTGTTCAACTCACAGCTCAAGTACAA\t6AEEEEEEAEEAEEEEAAEEEEEEEEEAEEAEEAAEE<EEEEEEEEEAEEEEEEEAAEEAAAEAEEAEAE/\tMD:Z:71\tNH:i:1\tHI:i:1\tNM:i:0\tSM:i:36\tXQ:i:40\tX2:i:0\tXO:Z:UU\n",
    "5)NS500451:flag-is-forward:HWKTMBGXX:1:11101:24260:1121:CTGTTCAT\t16\t5\t100\t36\t71M\t*\t0\t0\tTCCACCACAATCTTACCATCCTTCCTCCAGACCACATCGCGTTCTTTGTTCAACTCACAGCTCAAGTACAA\t6AEEEEEEAEEAEEEEAAEEEEEEEEEAEEAEEAAEE<EEEEEEEEEAEEEEEEEAAEEAAAEAEEAEAE/\tMD:Z:71\tNH:i:1\tHI:i:1\tNM:i:0\tSM:i:36\tXQ:i:40\tX2:i:0\tXO:Z:UU\n",
    "6)NS500451:flag-is-reverse:HWKTMBGXX:1:11101:24260:1121:CTGTTCAA\t0\t6\t100\t36\t71M\t*\t0\t0\tTCCACCACAATCTTACCATCCTTCCTCCAGACCACATCGCGTTCTTTGTTCAACTCACAGCTCAAGTACAA\t6AEEEEEEAEEAEEEEAAEEEEEEEEEAEEAEEAAEE<EEEEEEEEEAEEEEEEEAAEEAAAEAEEAEAE/\tMD:Z:71\tNH:i:1\tHI:i:1\tNM:i:0\tSM:i:36\tXQ:i:40\tX2:i:0\tXO:Z:UU\n",
    "7)NS500451:forward&has-s:HWKTMBGXX:1:11101:24260:1121:CTGTTCTA\t16\t6\t100\t36\t40S71M\t*\t0\t0\tTCCACCACAATCTTACCATCCTTCCTCCAGACCACATCGCGTTCTTTGTTCAACTCACAGCTCAAGTACAA\t6AEEEEEEAEEAEEEEAAEEEEEEEEEAEEAEEAAEE<EEEEEEEEEAEEEEEEEAAEEAAAEAEEAEAE/\tMD:Z:71\tNH:i:1\tHI:i:1\tNM:i:0\tSM:i:36\tXQ:i:40\tX2:i:0\tXO:Z:UU\n",
    "8)NS500451:forward&noaction:HWKTMBGXX:1:11101:24260:1121:CTGTTCTC\t0\t8\t100\t36\t71M40S\t*\t0\t0\tTCCACCACAATCTTACCATCCTTCCTCCAGACCACATCGCGTTCTTTGTTCAACTCACAGCTCAAGTACAA\t6AEEEEEEAEEAEEEEAAEEEEEEEEEAEEAEEAAEE<EEEEEEEEEAEEEEEEEAAEEAAAEAEEAEAE/\tMD:Z:71\tNH:i:1\tHI:i:1\tNM:i:0\tSM:i:36\tXQ:i:40\tX2:i:0\tXO:Z:UU\n",
    "9)NS500451:forward&has-s:HWKTMBGXX:1:11101:24260:1121:CTGTTCTC\t16\t9\t100\t36\t5S71M40S\t*\t0\t0\tTCCACCACAATCTTACCATCCTTCCTCCAGACCACATCGCGTTCTTTGTTCAACTCACAGCTCAAGTACAA\t6AEEEEEEAEEAEEEEAAEEEEEEEEEAEEAEEAAEE<EEEEEEEEEAEEEEEEEAAEEAAAEAEEAEAE/\tMD:Z:71\tNH:i:1\tHI:i:1\tNM:i:0\tSM:i:36\tXQ:i:40\tX2:i:0\tXO:Z:UU\n",
    "10)NS500451:forward&has-s:HWKTMBGXX:1:11101:24260:1121:CTGTTCTC\t0\t10\t100\t36\t5S71M40S\t*\t0\t0\tTCCACCACAATCTTACCATCCTTCCTCCAGACCACATCGCGTTCTTTGTTCAACTCACAGCTCAAGTACAA\t6AEEEEEEAEEAEEEEAAEEEEEEEEEAEEAEEAAEE<EEEEEEEEEAEEEEEEEAAEEAAAEAEEAEAE/\tMD:Z:71\tNH:i:1\tHI:i:1\tNM:i:0\tSM:i:36\tXQ:i:40\tX2:i:0\tXO:Z:UU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test output\n",
    "cat test_file_undetermine.sam \n",
    "4)NS500451:umi-not-in-dictionary:HWKTMBGXX:1:11101:24260:1121:TTTTTTTT\t16\t4\t100\t36\t71M\t*\t0\t0\tTCCACCACAATCTTACCATCCTTCCTCCAGACCACATCGCGTTCTTTGTTCAACTCACAGCTCAAGTACAA\t6AEEEEEEAEEAEEEEAAEEEEEEEEEAEEAEEAAEE<EEEEEEEEEAEEEEEEEAAEEAAAEAEEAEAE/\tMD:Z:71\tNH:i:1\tHI:i:1\tNM:i:0\tSM:i:36\tXQ:i:40\tX2:i:0\tXO:Z:UU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Directory with files to run real code on\n",
    "\n",
    "/projects/bgmp/shared/deduper\n",
    "Dataset1.sam  \n",
    "Dataset2.sam  \n",
    "Dataset3.sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Copied files to own directory\n",
    "\n",
    "/projects/bgmp/mdriskil\n",
    "cp Data*.sam /projects/bgmp/mdriskil/deduper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "First sorting the following sam files with SamTools: Dataset1.sam  Dataset2.sam  Dataset3.sam\n",
    "\n",
    "nano samtools_sort.slurm\n",
    "\n",
    "##################################################################################################################\n",
    "#!/usr/bin/env bash\n",
    "#SBATCH --partition=short    ### Partition\n",
    "#SBATCH --job-name=sam_view.job  ### Job Name\n",
    "#SBATCH --output=sam_view.job.out    ### File in which to store job output\n",
    "#SBATCH --time=0-23:00:00   ### Wall clock time limit in Days-HH:MM:SS\n",
    "#SBATCH --nodes=1           ### Number of nodes needed for the job\n",
    "#SBATCH --ntasks-per-node=28 ### Number of tasks to be launcged per Node\n",
    "\n",
    "module purge\n",
    "module load samtools/1.5\n",
    "\n",
    "cd /projects/bgmp/mdriskil/deduper\n",
    "\n",
    "files=`ls -1 ./*.sam`\n",
    "for file in ${files}; do\n",
    "         trimmedfilename=`echo ${file} | cut -d \"/\" -f2 | cut -d \".\" -f1`;\n",
    "samtools sort -o sorted_${trimmedfilename}.sam -O sam ${file};\n",
    "\n",
    "done\n",
    "exit\n",
    "\n",
    "##################################################################################################################\n",
    "\n",
    "chmod 755 samtools_sort.slurm\n",
    "sbatch samtools_sort.slurm\n",
    "\n",
    "##################################################################################################################\n",
    "\n",
    "output \n",
    "sorted_Dataset1.sam\n",
    "sorted_Dataset2.sam\n",
    "sorted_Dataset3.sam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Making sure files sorted correctly\n",
    "\n",
    "cat sorted_Dataset1.sam | grep -v \"^@\" | cut -f3 | uniq -c\n",
    "1013180 2\n",
    "\n",
    "cat sorted_Dataset2.sam | grep -v \"^@\" | cut -f3 | uniq -c\n",
    "1382109 2\n",
    "\n",
    "cat sorted_Dataset3.sam | grep -v \"^@\" | cut -f3 | uniq -c\n",
    " 239922 1\n",
    "1278754 2\n",
    " 184971 3\n",
    " 208866 4\n",
    " 183985 5\n",
    " 169727 6\n",
    " 577855 7\n",
    " 266089 8\n",
    " 262789 9\n",
    " 191431 10\n",
    " 604610 11\n",
    " 122285 12\n",
    " 160159 13\n",
    " 131529 14\n",
    " 167429 15\n",
    " 129414 16\n",
    " 194872 17\n",
    "  96470 18\n",
    " 229876 19\n",
    " 104108 X\n",
    "    736 Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Actual code (driskill_deduper.py) going to run on Dataset1.sam  Dataset2.sam  Dataset3.sam\n",
    "\n",
    "nano driskill_deduper.py\n",
    "\n",
    "##################################################################################################################\n",
    "\n",
    "\n",
    "#!/usr/bin/env python\n",
    "import argparse\n",
    "\n",
    "def get_arguments():\n",
    "    parser = argparse.ArgumentParser(description='k-mer size program')\n",
    "    parser.add_argument(\"-f\", \"--file\", help=\"input string\", required=True, type=str)\n",
    "    parser.add_argument(\"-o\", \"--out_file\", help=\"input string\", required=True, type=str)\n",
    "    parser.add_argument(\"-u\", \"--UMI_file\", help=\"input string\", required=True, type=str)\n",
    "    return parser.parse_args()\n",
    "    \n",
    "args = get_arguments()\n",
    "file = args.file\n",
    "out_file = args.out_file\n",
    "UMI_file = args.UMI_file\n",
    "\n",
    "\n",
    "import re\n",
    "import sys\n",
    "import os\n",
    "\n",
    "UMI_dict={}\n",
    "for line in open(UMI_file).readlines():\n",
    "    umi=line.strip()\n",
    "    UMI_dict[umi]=None\n",
    "\n",
    "ctr=1\n",
    "\n",
    "unique_dict={}\n",
    "current_rname=\"\"\n",
    "previous_rname=\"\"\n",
    "\n",
    "ctr_umi_notin_dict=0\n",
    "forward_reads=0\n",
    "reverse_reads=0\n",
    "unique_reads=0\n",
    "###################################################################################################################\n",
    "\n",
    "def pair_end_reads(flag):\n",
    "    if((int(flag) & 1) == 1):\n",
    "        sys.exit(\"Error, file contains pair-end reads\")\n",
    "    else:\n",
    "        return True \n",
    "\n",
    "def forward_adjust(pos):\n",
    "    softclip=re.search(r\"^(\\d+)S\", cigar)\n",
    "    if softclip is None:\n",
    "        softclip=softclip\n",
    "    else:\n",
    "        s1=int(softclip.group(1))\n",
    "        pos=pos-s1\n",
    "\n",
    "    string=current_rname+UMI+str(pos)+\"Plus\"\n",
    "    return string\n",
    "\n",
    "def reverse_adjust(pos):\n",
    "    pos=pos+total_S+total_M+total_D+total_N-1\n",
    "\n",
    "    string=current_rname+UMI+str(pos)+\"Minus\"\n",
    "    return string\n",
    "\n",
    "###################################################################################################################\n",
    "\n",
    "with open (file, \"r\") as fh, \\\n",
    "open(out_file + '_deduped.sam', 'w') as PCR_removed, \\\n",
    "open(out_file + '_undetermine.sam', 'w') as undetermined, \\\n",
    "open(out_file + '_count_data', 'w') as count_data:\n",
    "    \n",
    "###################################################################################################################\n",
    "    \n",
    "    for line in fh:\n",
    "        if line.startswith(\"@\"):\n",
    "            PCR_removed.write(line)\n",
    "            continue\n",
    "        else:\n",
    "            \n",
    "            parts = line.split(\"\\t\")#this splits all the colums in the line into lists(parts)\n",
    "            qname=parts[0]\n",
    "            flag=parts[1]\n",
    "            pair_end_reads(flag)\n",
    "            \n",
    "            current_rname=parts[2]\n",
    "            \n",
    "            if ctr==1:\n",
    "                previous_rname=current_rname\n",
    "            ctr+=1\n",
    "            \n",
    "            if current_rname != previous_rname:\n",
    "                previous_rname=current_rname\n",
    "                del unique_dict\n",
    "                unique_dict={}\n",
    "                \n",
    "            pos=int(parts[3])\n",
    "            cigar=parts[5]\n",
    "            rnext=parts[6]            \n",
    "            \n",
    "            \n",
    "            S = re.findall(r'(\\d+)S$', cigar)#finds all end S's\n",
    "            S=list(map(int,S))\n",
    "            total_S = sum([int(i) for i in S])\n",
    "            \n",
    "            M = re.findall(r\"(\\d+)M\", cigar)\n",
    "            M = list(map(int,M))\n",
    "            total_M = sum([int(i) for i in M])\n",
    "            \n",
    "            D = re.findall(r\"(\\d+)D\", cigar)\n",
    "            D = list(map(int,D))\n",
    "            total_D = sum([int(i) for i in D])\n",
    "            \n",
    "            N = re.findall(r\"(\\d+)N\", cigar)\n",
    "            N = list(map(int,N))\n",
    "            total_N = sum([int(i) for i in N])\n",
    "            \n",
    "            qname_parts=qname.split(\":\")\n",
    "            UMI=qname_parts[7]\n",
    "            \n",
    "###################################################################################################################\n",
    "                           \n",
    "\n",
    "            if UMI not in UMI_dict.keys():\n",
    "                ctr_umi_notin_dict+=1\n",
    "                undetermined.write(line)\n",
    "            else:\n",
    "                if UMI in UMI_dict.keys():\n",
    "\n",
    "###################################################################################################################\n",
    "\n",
    "                    if((int(flag) & 16) != 16):\n",
    "                        forward_reads+=1\n",
    "                        string=forward_adjust(pos)\n",
    "                        #print(string)\n",
    "\n",
    "###################################################################################################################\n",
    "\n",
    "                    \n",
    "                    if((int(flag) & 16) == 16):\n",
    "                        reverse_reads+=1\n",
    "                        string=reverse_adjust(pos)\n",
    "                        #print(string)\n",
    "                        \n",
    "###################################################################################################################\n",
    "\n",
    "                    \n",
    "                    if string not in unique_dict:\n",
    "                        unique_reads+=1\n",
    "                        unique_dict[string]=None\n",
    "                        print(unique_dict)\n",
    "                        PCR_removed.write(line)\n",
    "                            \n",
    "\n",
    "###################################################################################################################\n",
    "\n",
    "    count_data.write(\"{}\\n{}\\n{}\\n{}\\n{}\\n{}\\n{}\\n{}\\n\".format(\"UMI Not Found in Dictionary\", ctr_umi_notin_dict, \\\n",
    "                                                               \"Number of Forward Reads\", forward_reads, \\\n",
    "                                                               \"Number of Reverse Reads\",  reverse_reads, \\\n",
    "                                                               \"Number of Unique Reads Found\", unique_reads)) \n",
    "\n",
    "##################################################################################################################\n",
    "\n",
    "chmod 755 driskill_deduper.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat STL96.txt\n",
    "AACGCCAT\n",
    "AAGGTACG\n",
    "AATTCCGG\n",
    "ACACAGAG\n",
    "ACACTCAG\n",
    "ACACTGTG\n",
    "ACAGGACA\n",
    "ACCTGTAG\n",
    "ACGAAGGT\n",
    "ACGACTTG\n",
    "ACGTCAAC\n",
    "ACGTCATG\n",
    "ACTGTCAG\n",
    "ACTGTGAC\n",
    "AGACACTC\n",
    "AGAGGAGA\n",
    "AGCATCGT\n",
    "AGCATGGA\n",
    "AGCTACCA\n",
    "AGCTCTAG\n",
    "AGGACAAC\n",
    "AGGACATG\n",
    "AGGTTGCT\n",
    "AGTCGAGA\n",
    "AGTGCTGT\n",
    "ATAAGCGG\n",
    "ATCCATGG\n",
    "ATCGAACC\n",
    "ATCGCGTA\n",
    "ATCGTTGG\n",
    "CAACGATC\n",
    "CAACGTTG\n",
    "CAACTGGT\n",
    "CAAGTCGT\n",
    "CACACACA\n",
    "CAGTACTG\n",
    "CATCAGCA\n",
    "CATCGTTC\n",
    "CCAAGGTT\n",
    "CCTAGCTT\n",
    "CGATTACG\n",
    "CGCCTATT\n",
    "CGTTCCAT\n",
    "CGTTGGAT\n",
    "CTACGTTC\n",
    "CTACTCGT\n",
    "CTAGAGGA\n",
    "CTAGGAAG\n",
    "CTAGGTAC\n",
    "CTCAGTCT\n",
    "CTGACTGA\n",
    "CTGAGTGT\n",
    "CTGATGTG\n",
    "CTGTTCAC\n",
    "CTTCGTTG\n",
    "GAACAGGT\n",
    "GAAGACCA\n",
    "GAAGTGCA\n",
    "GACATGAG\n",
    "GAGAAGAG\n",
    "GAGAAGTC\n",
    "GATCCTAG\n",
    "GATGTCGT\n",
    "GCCGATAT\n",
    "GCCGATTA\n",
    "GCGGTATT\n",
    "GGAATTGG\n",
    "GGATAACG\n",
    "GGCCTAAT\n",
    "GGCGTATT\n",
    "GTCTTGTC\n",
    "GTGATGAG\n",
    "GTGATGTC\n",
    "GTGTACTG\n",
    "GTGTAGTC\n",
    "GTTCACCT\n",
    "GTTCTGCT\n",
    "GTTGTCGA\n",
    "TACGAACC\n",
    "TAGCAAGG\n",
    "TAGCTAGC\n",
    "TAGGTTCG\n",
    "TATAGCGC\n",
    "TCAGGACT\n",
    "TCCACATC\n",
    "TCGACTTC\n",
    "TCGTAGGT\n",
    "TCGTCATC\n",
    "TGAGACTC\n",
    "TGAGAGTG\n",
    "TGAGTGAG\n",
    "TGCTTGGA\n",
    "TGGAGTAG\n",
    "TGTGTGTG\n",
    "TTCGCCTA\n",
    "TTCGTTCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "created slurm to run on talapas to dedupe sorted_Dataset1.sam sorted_Dataset2.sam sorted_Dataset3.sam\n",
    "\n",
    "nano dedupe.slurm\n",
    "\n",
    "##################################################################################################################\n",
    "\n",
    "#!/usr/bin/env bash\n",
    "#SBATCH --partition=short    ### Partition\n",
    "#SBATCH --job-name=dedupejob  ### Job Name\n",
    "#SBATCH --output=dedupejob.out    ### File in which to store job output\n",
    "#SBATCH --time=0-00:30:00   ### Wall clock time limit in Days-HH:MM:SS\n",
    "#SBATCH --nodes=1           ### Number of nodes needed for the job\n",
    "#SBATCH --ntasks-per-node=14 ### Number of tasks to be launcged per Node\n",
    "\n",
    "cd /projects/bgmp/mdriskil/deduper\n",
    "\n",
    "files=`ls -1 ./sorted_*`\n",
    "for file in ${files}; do\n",
    "         trimmedfilename=`echo ${file} | cut -d \"/\" -f2 | cut -d \"_\" -f2 | cut -d \".\" -f1`;\n",
    "./driskill_deduper.py -f ${file} -o ${trimmedfilename} -u STL96.txt;\n",
    "done\n",
    "exit\n",
    "\n",
    "chmod 755 dedupe.slurm\n",
    "sbatch dedupe.slurm\n",
    "\n",
    "###################################################################################################################\n",
    "output files\n",
    "\n",
    "Dataset1_count_data\n",
    "Dataset1_deduped.sam\n",
    "Dataset1_undetermine.sam\n",
    "\n",
    "Dataset2_count_data\n",
    "Dataset2_deduped.sam\n",
    "Dataset2_undetermine.sam\n",
    "\n",
    "Dataset3_count_data\n",
    "Dataset3_deduped.sam\n",
    "Dataset3_undetermine.sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Number of lines that were unique/deduplicated\n",
    "cat Dataset1_deduped.sam | grep -v \"^@\" | wc -l\n",
    "635985\n",
    "\n",
    "cat Dataset2_deduped.sam | grep -v \"^@\" | wc -l\n",
    "744188\n",
    "\n",
    "cat Dataset3_deduped.sam | grep -v \"^@\" | wc -l\n",
    "4053644\n",
    "##################################################################################################################\n",
    "\n",
    "\n",
    "Number of lines that that had umis that were not in the dictionary\n",
    "cat Dataset1_undetermine.sam | grep -v \"^@\" | wc -l\n",
    "8190\n",
    "\n",
    "cat Dataset2_undetermine.sam | grep -v \"^@\" | wc -l\n",
    "9319\n",
    "\n",
    "cat Dataset3_undetermine.sam | grep -v \"^@\" | wc -l\n",
    "48939\n",
    "##################################################################################################################\n",
    "\n",
    "\n",
    "Count data for all the files\n",
    "cat Dataset1_count_data \n",
    "UMI Not Found in Dictionary\n",
    "8190\n",
    "Number of Forward Reads\n",
    "1004945\n",
    "Number of Reverse Reads\n",
    "45\n",
    "Number of Unique Reads Found\n",
    "635985\n",
    "\n",
    "cat Dataset2_count_data \n",
    "UMI Not Found in Dictionary\n",
    "9319\n",
    "Number of Forward Reads\n",
    "1372737\n",
    "Number of Reverse Reads\n",
    "53\n",
    "Number of Unique Reads Found\n",
    "744188\n",
    "\n",
    "cat Dataset3_count_data \n",
    "UMI Not Found in Dictionary\n",
    "48939\n",
    "Number of Forward Reads\n",
    "5658335\n",
    "Number of Reverse Reads\n",
    "13876\n",
    "Number of Unique Reads Found\n",
    "4053644\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
